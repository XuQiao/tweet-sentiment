{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(train, multiple = 1):\n",
    "    def aug(row):\n",
    "        tweet = row['text']\n",
    "        selected_text = row['selected_text']\n",
    "        idx = tweet.find(selected_text) \n",
    "        if idx>=0:\n",
    "            new_tweets = []\n",
    "            prev = tweet[:idx].split()\n",
    "            after = tweet[idx+len(selected_text):].split()\n",
    "            pool = [(i,j) for i in range(len(prev)+1) for j in range(len(after)+1)]\n",
    "            pool.remove((len(prev),len(after)))\n",
    "            if len(pool) == 0:\n",
    "                return None\n",
    "            for r in np.random.choice(len(pool), multiple):\n",
    "                r1, r2 = pool[r]\n",
    "                start = ''\n",
    "                end = ''\n",
    "                if r1 > 0:\n",
    "                    start =' '.join(prev[r1:]) + ' '\n",
    "                if r2 > 0:\n",
    "                    end = ' '+' '.join(after[:r2])\n",
    "                \n",
    "                new_tweets.append(start+selected_text+end)\n",
    "            if len(new_tweets) > 0:\n",
    "                return new_tweets\n",
    "            return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    train_aug = {'text':[],'selected_text':[], 'sentiment':[], 'textID':[]}\n",
    "    for row in train.iterrows():\n",
    "        row = row[1]\n",
    "        new_tweets = aug(row)\n",
    "        if new_tweets:\n",
    "            for new_tweet in new_tweets:\n",
    "                train_aug['text'].append(new_tweet)\n",
    "                train_aug['selected_text'].append(row['selected_text'])\n",
    "                train_aug['sentiment'].append(row['sentiment'])\n",
    "                train_aug['textID'].append(row['textID'])\n",
    "    train_aug = pd.DataFrame(train_aug).dropna()\n",
    "    return train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/qiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/qiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/qiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/qiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/qiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tokenizers \n",
    "import transformers\n",
    "\n",
    "ROBERTA_PATH = \"../input/roberta-base\"\n",
    "\n",
    "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "        vocab_file=f\"{ROBERTA_PATH}/vocab.json\", \n",
    "        merges_file=f\"{ROBERTA_PATH}/merges.txt\", \n",
    "        lowercase=True,\n",
    "        add_prefix_space=True\n",
    "    )\n",
    "\n",
    "model_config = transformers.BertConfig.from_pretrained(ROBERTA_PATH)\n",
    "model_config.output_hidden_states = True\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "MAX_LEN = 128\n",
    "VOCAB_SIZE = 50000\n",
    "EMBEDDING_DIM = 768\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    if len(selected_text) == 0:\n",
    "        selected_text = \" \"\n",
    "    if len(tweet) == 0:\n",
    "        tweet = \" \"\n",
    "        \n",
    "    tweet = \" \" + \" \".join(str(tweet).split(\" \"))\n",
    "    selected_text = \" \" + \" \".join(str(selected_text).split(\" \"))\n",
    "\n",
    "    len_st = len(selected_text) - 1\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "            \n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "\n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    input_ids_orig = tok_tweet.ids\n",
    "    tweet_offsets = tok_tweet.offsets\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "\n",
    "    targets_start = target_idx[0]\n",
    "    targets_end = target_idx[-1]\n",
    "\n",
    "    input_ids = [0] + [2] + [2] + input_ids_orig + [2]\n",
    "    token_type_ids = [0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offsets = [(0, 0)] * 3 + tweet_offsets + [(0, 0)]\n",
    "    targets_start += 3\n",
    "    targets_end += 3\n",
    "\n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([1] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "\n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TweetModel, self).__init__()\n",
    "        self.roberta = transformers.RobertaModel.from_pretrained(ROBERTA_PATH, config=model_config)\n",
    "        #self.embedding = self.roberta.get_input_embeddings()\n",
    "        #self.lstm = nn.LSTM(EMBEDDING_DIM, MAX_LEN // 2, batch_first=True, bidirectional=True)\n",
    "        self.drop_out = nn.Dropout(0.2)\n",
    "        self.l0 = nn.Linear(EMBEDDING_DIM * 2, 2)\n",
    "        torch.nn.init.normal_(self.l0.weight, std=0.05)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, _, out = self.roberta(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        out = torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out = self.drop_out(out)\n",
    "        logits = self.l0(out)\n",
    "\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.view((-1,start_logits.size(1)))\n",
    "        end_logits = end_logits.view((-1,end_logits.size(1)))\n",
    "\n",
    "        return start_logits, end_logits\n",
    "\n",
    "class TweetDataset:\n",
    "    def __init__(self, tweet, sentiment, selected_text):\n",
    "        self.tweet = tweet\n",
    "        self.sentiment = sentiment\n",
    "        self.selected_text = selected_text\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = process_data(\n",
    "            self.tweet[item], \n",
    "            self.selected_text[item], \n",
    "            self.sentiment[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
    "            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
    "            'orig_tweet': data[\"orig_tweet\"],\n",
    "            'orig_selected': data[\"orig_selected\"],\n",
    "            'sentiment': data[\"sentiment\"],\n",
    "            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    losses = utils.AverageMeter()\n",
    "    jaccards = utils.AverageMeter()\n",
    "\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    \n",
    "    for bi, d in enumerate(tk0):\n",
    "\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        offsets = d[\"offsets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs_start, outputs_end = model(\n",
    "            ids = ids,\n",
    "            mask = mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "        )\n",
    "        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        jaccard_scores = []\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            jaccard_score, _ = utils.calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                sentiment_val=tweet_sentiment,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                offsets=offsets[px],\n",
    "            )\n",
    "            jaccard_scores.append(jaccard_score)\n",
    "\n",
    "        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "        losses.update(loss.item(), ids.size(0))\n",
    "        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
    "        \n",
    "    del ids\n",
    "    del token_type_ids\n",
    "    del mask\n",
    "    del targets_start\n",
    "    del targets_end\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "def eval_fn(data_loader, model_pos, model_neg, device):\n",
    "    model_pos.eval()\n",
    "    model_neg.eval()\n",
    "    losses = utils.AverageMeter()\n",
    "    jaccards_pos = utils.AverageMeter()\n",
    "    jaccards_neg = utils.AverageMeter()\n",
    "    jaccards_full = utils.AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for bi, d in enumerate(tk0):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            sentiment = d[\"sentiment\"]\n",
    "            orig_selected = d[\"orig_selected\"]\n",
    "            orig_tweet = d[\"orig_tweet\"]\n",
    "            targets_start = d[\"targets_start\"]\n",
    "            targets_end = d[\"targets_end\"]\n",
    "            offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets_start = targets_start.to(device, dtype=torch.long)\n",
    "            targets_end = targets_end.to(device, dtype=torch.long)\n",
    "            outputs_start, outputs_end = model_pos(\n",
    "                ids=ids,\n",
    "                mask = mask,\n",
    "                token_type_ids = token_type_ids,\n",
    "            )\n",
    "            if sentiment == 'negative':\n",
    "                outputs_start, outputs_end = model_neg(\n",
    "                ids=ids,\n",
    "                mask = mask,\n",
    "                token_type_ids = token_type_ids,\n",
    "                )\n",
    "            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "            jaccard_scores_pos = []\n",
    "            jaccard_scores_neg = []\n",
    "            jaccard_scores_full = []\n",
    "            for px, tweet in enumerate(orig_tweet):\n",
    "                selected_tweet = orig_selected[px]\n",
    "                tweet_sentiment = sentiment[px]\n",
    "                if tweet_sentiment == 'neutral':\n",
    "                    jaccard_score = utils.jaccard(tweet, selected_tweet)\n",
    "                else:\n",
    "                    jaccard_score, _ = utils.calculate_jaccard_score(\n",
    "                        original_tweet=tweet,\n",
    "                        target_string=selected_tweet,\n",
    "                        sentiment_val=tweet_sentiment,\n",
    "                        idx_start=np.argmax(outputs_start[px, :]),\n",
    "                        idx_end=np.argmax(outputs_end[px, :]),\n",
    "                        offsets=offsets[px]\n",
    "                    )\n",
    "                    if tweet_sentiment == 'positive':\n",
    "                        jaccard_scores_pos.append(jaccard_score)\n",
    "                    if tweet_sentiment == 'negative':\n",
    "                        jaccard_scores_neg.append(jaccard_score)\n",
    "                jaccard_scores_full.append(jaccard_score)\n",
    "            jaccards_pos.update(np.mean(jaccard_scores_pos), ids.size(0))\n",
    "            jaccards_neg.update(np.mean(jaccard_scores_neg), ids.size(0))\n",
    "            jaccards_full.update(np.mean(jaccard_scores_full), ids.size(0))\n",
    "            losses.update(loss.item(), ids.size(0))\n",
    "            tk0.set_postfix(loss=losses.avg, jaccard_pos=jaccards_pos.avg,jaccard_neg=jaccards_neg.avg,jaccard_full=jaccards_full.avg)\n",
    "    \n",
    "    return jaccards_full.avg\n",
    "\n",
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = 0\n",
    "    #if (start_loss + end_loss) > 0:\n",
    "    #    total_loss = (start_loss * end_loss)/(start_loss + end_loss)\n",
    "    total_loss = (start_loss + end_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "indexes = []\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(train['text'],train['sentiment']):\n",
    "    indexes.append((train_index, test_index))\n",
    "\n",
    "def run(fold=0):\n",
    "    train_index, test_index = indexes[fold]\n",
    "    df_train, df_valid = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "    def prepare(sentiment=\"neutral\", df_train=df_train):\n",
    "        df_train = df_train[df_train['sentiment']==sentiment]\n",
    "        df_train = pd.concat([df_train, data_aug(df_train,0)], axis=0, sort=False)\n",
    "    \n",
    "        train_dataset = TweetDataset(\n",
    "            tweet=df_train.text.values,\n",
    "            sentiment=df_train.sentiment.values,\n",
    "            selected_text=df_train.selected_text.values\n",
    "        )\n",
    "\n",
    "        train_data_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            num_workers=8\n",
    "        )\n",
    "        model = TweetModel()\n",
    "        model.to(device)\n",
    "\n",
    "        num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_parameters, lr=5e-5)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=0, \n",
    "            num_training_steps=num_train_steps\n",
    "        )\n",
    "    \n",
    "        return train_data_loader, model, optimizer, scheduler\n",
    "    \n",
    "    \n",
    "    valid_dataset = TweetDataset(\n",
    "        tweet=df_valid.text.values,\n",
    "        sentiment=df_valid.sentiment.values,\n",
    "        selected_text=df_valid.selected_text.values\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    train_data_loader_pos, model_pos, optimizer_pos, scheduler_pos = prepare(sentiment=\"positive\",df_train=df_train)\n",
    "    train_data_loader_neg, model_neg, optimizer_neg, scheduler_neg = prepare(sentiment=\"negative\",df_train=df_train)\n",
    "\n",
    "    es = utils.EarlyStopping(patience=2)\n",
    "    print(f\"Training is Starting for fold={fold}\")  \n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_fn(train_data_loader_pos, model_pos, optimizer_pos, device, scheduler=scheduler_pos)\n",
    "        train_fn(train_data_loader_neg, model_neg, optimizer_neg, device, scheduler=scheduler_neg)\n",
    "        jaccard = eval_fn(valid_data_loader, model_pos, model_neg, device)\n",
    "        print(f\"Jaccard Score = {jaccard}\")\n",
    "        es(jaccard, model_neg)\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    torch.save(model_pos.state_dict(), f\"model_pos_{fold}.bin\")    \n",
    "    torch.save(model_neg.state_dict(), f\"model_neg_{fold}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000f30e3633841d6a432419ce2dda207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfb9489f767470387ee9975819f6beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=389.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977f4fed20df4b009782a9868789480b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiao/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/qiao/.local/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6616839207278371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c493cecb83024e628d11cdf1026695a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e140b8d2c6448fa5f766083dc95c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=389.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea690a0378884db186307f9cc00c8672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6598317705478718\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b0f8797d6948b99ef588c5f912a5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9577f29bbc6b4844902c2adab3dc8ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=389.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbdc96484284e9fbf32cc66ddaede01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6650412586958436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4495453aec2400dbe77da92f9aa7289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e8cc29e5944c3791c8f0637996343a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=389.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54db45d2ac4840fbbe5740393942498d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6607866024720374\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab88a64988842d1baf421f879bfbe5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b9a336f4df4490ab6837b293f5a714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=389.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b791e3bc840a5b7619241357684f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6559426732704476\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Training is Starting for fold=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a5b22946314b9bbf130cb8ae42ed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5274a5ae073f46ed83d34c2882919e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589fbc0c9efb4722830cac8ce2bc8577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6640782274918084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fffdb40228424cb38b0986512fe527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c731ead493e543b2a047910d8eb331b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048348214c91435886bea99a6cdaea7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6675965217206605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e742779d6844c25a640d7a9f910bac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c09705fade8416ba3862857fcda7243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b4e0b5c3974059af429e69642e4dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6610904117276689\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd506fee1504c3780ae4d3cb38d0026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b51328008f949abaee74e4eb20c1c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f8a636f6124bc8945ab7d53c419140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6651923639539626\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Training is Starting for fold=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97447c5057ab49d990f0cdb8f3e70956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4900dc3ba049e29e101b898a083408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f021d96116c4d12a8437e357b515cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6568427109673235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b602ca449247748a5ebb9dbfde2b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c4610782dc45dd8e6001480f1c155e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c037550309654ed0ba30da9863b2a1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6623645329557112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3191ba4c1dc640858fd0e1c5d42c6a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96a6de77d204184bae0dd9aed0fb091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e549f466c94f4067a681cc82e088c231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6556728645291514\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526c75ae9c9645ed9c1510c7c4caf8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baeb5d34e1a40dc9ea336e72a67d3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8238a7917a4e413fa07cb1551ef4cf0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6580427444580262\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Training is Starting for fold=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a5194809974c9d99ba0eaa6d887b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d5b4aeacbf4b198cd13c82d60c8a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fd1dc3a4cf428b86bec96b72919c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6628533901032867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66895fbf99f14da79847bb4298a78bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a056b88c761472f979efa20c881c34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a454bf430e0a4e36ab6f400ceb3747d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6665433732663466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811a6503bda849fc87e70477a79f0677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68ef256c4414498a30a66ada1b030d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcf744812464ebeb3dc161b93d89cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6611414329455548\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532946ac756a407f9d9b92078c7d347b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e3a3e2e5c8407e874cf0c3b1fafbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524610ae23484958b1df3b9f57345ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6554794321752979\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Training is Starting for fold=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd7fca7597c4ba5b197344bc0ad1f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac03a7c9722b44e998625e90984dd610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1572c84be0624234ad910f701e927680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6645527103556824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98780e4c3881480daff6531a8c9094b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d089c5cfc668438a823bab00724bd6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cda49784a94c3da87907dae2ff3af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6720174751714258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2071cb0777174c6fb8726e0a0b9d6b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f730ce33b742fab1a536667933a31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebccfdf9d7c8437fb4d44cb343dfd538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6645053018902134\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e73a554caac4b44aa8a8d8c26c9c5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fc8df000624292ba8a433eb3894bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09fba8c153147d8ba63348fcf1a7036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6637266027042422\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit():\n",
    "    df_test = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\n",
    "    df_test.loc[:, \"selected_text\"] = df_test.text.values\n",
    "    #device = torch.device(\"cpu\")\n",
    "\n",
    "    model1 = TweetModel()\n",
    "    model1.to(device)\n",
    "    model1.load_state_dict(torch.load(\"model_0.bin\"))\n",
    "    model1.eval()\n",
    "\n",
    "    model2 = TweetModel()\n",
    "    model2.to(device)\n",
    "    model2.load_state_dict(torch.load(\"model_1.bin\"))\n",
    "    model2.eval()\n",
    "\n",
    "    model3 = TweetModel()\n",
    "    model3.to(device)\n",
    "    model3.load_state_dict(torch.load(\"model_2.bin\"))\n",
    "    model3.eval()\n",
    "\n",
    "    model4 = TweetModel()\n",
    "    model4.to(device)\n",
    "    model4.load_state_dict(torch.load(\"model_3.bin\"))\n",
    "    model4.eval()\n",
    "\n",
    "    model5 = TweetModel()\n",
    "    model5.to(device)\n",
    "    model5.load_state_dict(torch.load(\"model_4.bin\"))\n",
    "    model5.eval()\n",
    "    final_output = []\n",
    "\n",
    "    test_dataset = TweetDataset(\n",
    "            tweet=df_test.text.values,\n",
    "            sentiment=df_test.sentiment.values,\n",
    "            selected_text=df_test.selected_text.values\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        num_workers=1\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for bi, d in enumerate(tk0):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            sentiment = d[\"sentiment\"]\n",
    "            orig_selected = d[\"orig_selected\"]\n",
    "            orig_tweet = d[\"orig_tweet\"]\n",
    "            targets_start = d[\"targets_start\"]\n",
    "            targets_end = d[\"targets_end\"]\n",
    "            offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets_start = targets_start.to(device, dtype=torch.long)\n",
    "            targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs_start1, outputs_end1 = model1(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            outputs_start2, outputs_end2 = model2(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            outputs_start3, outputs_end3 = model3(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            outputs_start4, outputs_end4 = model4(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            outputs_start5, outputs_end5 = model5(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            outputs_start = (\n",
    "                outputs_start1 \n",
    "                + outputs_start2 \n",
    "                + outputs_start3 \n",
    "                + outputs_start4 \n",
    "                + outputs_start5\n",
    "            ) / 5\n",
    "            outputs_end = (\n",
    "                outputs_end1 \n",
    "                + outputs_end2 \n",
    "                + outputs_end3 \n",
    "                + outputs_end4 \n",
    "                + outputs_end5\n",
    "            ) / 5\n",
    "\n",
    "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "\n",
    "            for px, tweet in enumerate(orig_tweet):\n",
    "                selected_tweet = orig_selected[px]\n",
    "                tweet_sentiment = sentiment[px]\n",
    "                if tweet_sentiment == 'neutral':\n",
    "                    output_sentence = tweet\n",
    "                else:\n",
    "                    _, output_sentence = utils.calculate_jaccard_score(\n",
    "                        original_tweet=tweet,\n",
    "                        target_string=selected_tweet,\n",
    "                        sentiment_val=tweet_sentiment,\n",
    "                        idx_start=np.argmax(outputs_start[px, :]),\n",
    "                        idx_end=np.argmax(outputs_end[px, :]),\n",
    "                        offsets=offsets[px]\n",
    "                )\n",
    "                final_output.append(output_sentence)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TweetModel:\n\tUnexpected key(s) in state_dict: \"i0.weight\", \"i0.bias\", \"unet.inc.double_conv.0.weight\", \"unet.inc.double_conv.0.bias\", \"unet.inc.double_conv.1.weight\", \"unet.inc.double_conv.1.bias\", \"unet.inc.double_conv.1.running_mean\", \"unet.inc.double_conv.1.running_var\", \"unet.inc.double_conv.1.num_batches_tracked\", \"unet.inc.double_conv.3.weight\", \"unet.inc.double_conv.3.bias\", \"unet.inc.double_conv.4.weight\", \"unet.inc.double_conv.4.bias\", \"unet.inc.double_conv.4.running_mean\", \"unet.inc.double_conv.4.running_var\", \"unet.inc.double_conv.4.num_batches_tracked\", \"unet.down1.maxpool_conv.1.double_conv.0.weight\", \"unet.down1.maxpool_conv.1.double_conv.0.bias\", \"unet.down1.maxpool_conv.1.double_conv.1.weight\", \"unet.down1.maxpool_conv.1.double_conv.1.bias\", \"unet.down1.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down1.maxpool_conv.1.double_conv.1.running_var\", \"unet.down1.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down1.maxpool_conv.1.double_conv.3.weight\", \"unet.down1.maxpool_conv.1.double_conv.3.bias\", \"unet.down1.maxpool_conv.1.double_conv.4.weight\", \"unet.down1.maxpool_conv.1.double_conv.4.bias\", \"unet.down1.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down1.maxpool_conv.1.double_conv.4.running_var\", \"unet.down1.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.down2.maxpool_conv.1.double_conv.0.weight\", \"unet.down2.maxpool_conv.1.double_conv.0.bias\", \"unet.down2.maxpool_conv.1.double_conv.1.weight\", \"unet.down2.maxpool_conv.1.double_conv.1.bias\", \"unet.down2.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down2.maxpool_conv.1.double_conv.1.running_var\", \"unet.down2.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down2.maxpool_conv.1.double_conv.3.weight\", \"unet.down2.maxpool_conv.1.double_conv.3.bias\", \"unet.down2.maxpool_conv.1.double_conv.4.weight\", \"unet.down2.maxpool_conv.1.double_conv.4.bias\", \"unet.down2.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down2.maxpool_conv.1.double_conv.4.running_var\", \"unet.down2.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.down3.maxpool_conv.1.double_conv.0.weight\", \"unet.down3.maxpool_conv.1.double_conv.0.bias\", \"unet.down3.maxpool_conv.1.double_conv.1.weight\", \"unet.down3.maxpool_conv.1.double_conv.1.bias\", \"unet.down3.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down3.maxpool_conv.1.double_conv.1.running_var\", \"unet.down3.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down3.maxpool_conv.1.double_conv.3.weight\", \"unet.down3.maxpool_conv.1.double_conv.3.bias\", \"unet.down3.maxpool_conv.1.double_conv.4.weight\", \"unet.down3.maxpool_conv.1.double_conv.4.bias\", \"unet.down3.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down3.maxpool_conv.1.double_conv.4.running_var\", \"unet.down3.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.down4.maxpool_conv.1.double_conv.0.weight\", \"unet.down4.maxpool_conv.1.double_conv.0.bias\", \"unet.down4.maxpool_conv.1.double_conv.1.weight\", \"unet.down4.maxpool_conv.1.double_conv.1.bias\", \"unet.down4.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down4.maxpool_conv.1.double_conv.1.running_var\", \"unet.down4.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down4.maxpool_conv.1.double_conv.3.weight\", \"unet.down4.maxpool_conv.1.double_conv.3.bias\", \"unet.down4.maxpool_conv.1.double_conv.4.weight\", \"unet.down4.maxpool_conv.1.double_conv.4.bias\", \"unet.down4.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down4.maxpool_conv.1.double_conv.4.running_var\", \"unet.down4.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.up1.conv.double_conv.0.weight\", \"unet.up1.conv.double_conv.0.bias\", \"unet.up1.conv.double_conv.1.weight\", \"unet.up1.conv.double_conv.1.bias\", \"unet.up1.conv.double_conv.1.running_mean\", \"unet.up1.conv.double_conv.1.running_var\", \"unet.up1.conv.double_conv.1.num_batches_tracked\", \"unet.up1.conv.double_conv.3.weight\", \"unet.up1.conv.double_conv.3.bias\", \"unet.up1.conv.double_conv.4.weight\", \"unet.up1.conv.double_conv.4.bias\", \"unet.up1.conv.double_conv.4.running_mean\", \"unet.up1.conv.double_conv.4.running_var\", \"unet.up1.conv.double_conv.4.num_batches_tracked\", \"unet.up2.conv.double_conv.0.weight\", \"unet.up2.conv.double_conv.0.bias\", \"unet.up2.conv.double_conv.1.weight\", \"unet.up2.conv.double_conv.1.bias\", \"unet.up2.conv.double_conv.1.running_mean\", \"unet.up2.conv.double_conv.1.running_var\", \"unet.up2.conv.double_conv.1.num_batches_tracked\", \"unet.up2.conv.double_conv.3.weight\", \"unet.up2.conv.double_conv.3.bias\", \"unet.up2.conv.double_conv.4.weight\", \"unet.up2.conv.double_conv.4.bias\", \"unet.up2.conv.double_conv.4.running_mean\", \"unet.up2.conv.double_conv.4.running_var\", \"unet.up2.conv.double_conv.4.num_batches_tracked\", \"unet.up3.conv.double_conv.0.weight\", \"unet.up3.conv.double_conv.0.bias\", \"unet.up3.conv.double_conv.1.weight\", \"unet.up3.conv.double_conv.1.bias\", \"unet.up3.conv.double_conv.1.running_mean\", \"unet.up3.conv.double_conv.1.running_var\", \"unet.up3.conv.double_conv.1.num_batches_tracked\", \"unet.up3.conv.double_conv.3.weight\", \"unet.up3.conv.double_conv.3.bias\", \"unet.up3.conv.double_conv.4.weight\", \"unet.up3.conv.double_conv.4.bias\", \"unet.up3.conv.double_conv.4.running_mean\", \"unet.up3.conv.double_conv.4.running_var\", \"unet.up3.conv.double_conv.4.num_batches_tracked\", \"unet.up4.conv.double_conv.0.weight\", \"unet.up4.conv.double_conv.0.bias\", \"unet.up4.conv.double_conv.1.weight\", \"unet.up4.conv.double_conv.1.bias\", \"unet.up4.conv.double_conv.1.running_mean\", \"unet.up4.conv.double_conv.1.running_var\", \"unet.up4.conv.double_conv.1.num_batches_tracked\", \"unet.up4.conv.double_conv.3.weight\", \"unet.up4.conv.double_conv.3.bias\", \"unet.up4.conv.double_conv.4.weight\", \"unet.up4.conv.double_conv.4.bias\", \"unet.up4.conv.double_conv.4.running_mean\", \"unet.up4.conv.double_conv.4.running_var\", \"unet.up4.conv.double_conv.4.num_batches_tracked\", \"unet.outc.conv.weight\", \"unet.outc.conv.bias\". \n\tsize mismatch for l0.weight: copying a param with shape torch.Size([128, 1536]) from checkpoint, the shape in current model is torch.Size([2, 1536]).\n\tsize mismatch for l0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cbabe1fcf31f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../output/sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'selected_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a5644dbd8ade>\u001b[0m in \u001b[0;36msubmit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_0.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TweetModel:\n\tUnexpected key(s) in state_dict: \"i0.weight\", \"i0.bias\", \"unet.inc.double_conv.0.weight\", \"unet.inc.double_conv.0.bias\", \"unet.inc.double_conv.1.weight\", \"unet.inc.double_conv.1.bias\", \"unet.inc.double_conv.1.running_mean\", \"unet.inc.double_conv.1.running_var\", \"unet.inc.double_conv.1.num_batches_tracked\", \"unet.inc.double_conv.3.weight\", \"unet.inc.double_conv.3.bias\", \"unet.inc.double_conv.4.weight\", \"unet.inc.double_conv.4.bias\", \"unet.inc.double_conv.4.running_mean\", \"unet.inc.double_conv.4.running_var\", \"unet.inc.double_conv.4.num_batches_tracked\", \"unet.down1.maxpool_conv.1.double_conv.0.weight\", \"unet.down1.maxpool_conv.1.double_conv.0.bias\", \"unet.down1.maxpool_conv.1.double_conv.1.weight\", \"unet.down1.maxpool_conv.1.double_conv.1.bias\", \"unet.down1.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down1.maxpool_conv.1.double_conv.1.running_var\", \"unet.down1.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down1.maxpool_conv.1.double_conv.3.weight\", \"unet.down1.maxpool_conv.1.double_conv.3.bias\", \"unet.down1.maxpool_conv.1.double_conv.4.weight\", \"unet.down1.maxpool_conv.1.double_conv.4.bias\", \"unet.down1.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down1.maxpool_conv.1.double_conv.4.running_var\", \"unet.down1.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.down2.maxpool_conv.1.double_conv.0.weight\", \"unet.down2.maxpool_conv.1.double_conv.0.bias\", \"unet.down2.maxpool_conv.1.double_conv.1.weight\", \"unet.down2.maxpool_conv.1.double_conv.1.bias\", \"unet.down2.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down2.maxpool_conv.1.double_conv.1.running_var\", \"unet.down2.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down2.maxpool_conv.1.double_conv.3.weight\", \"unet.down2.maxpool_conv.1.double_conv.3.bias\", \"unet.down2.maxpool_conv.1.double_conv.4.weight\", \"unet.down2.maxpool_conv.1.double_conv.4.bias\", \"unet.down2.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down2.maxpool_conv.1.double_conv.4.running_var\", \"unet.down2.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.down3.maxpool_conv.1.double_conv.0.weight\", \"unet.down3.maxpool_conv.1.double_conv.0.bias\", \"unet.down3.maxpool_conv.1.double_conv.1.weight\", \"unet.down3.maxpool_conv.1.double_conv.1.bias\", \"unet.down3.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down3.maxpool_conv.1.double_conv.1.running_var\", \"unet.down3.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down3.maxpool_conv.1.double_conv.3.weight\", \"unet.down3.maxpool_conv.1.double_conv.3.bias\", \"unet.down3.maxpool_conv.1.double_conv.4.weight\", \"unet.down3.maxpool_conv.1.double_conv.4.bias\", \"unet.down3.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down3.maxpool_conv.1.double_conv.4.running_var\", \"unet.down3.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.down4.maxpool_conv.1.double_conv.0.weight\", \"unet.down4.maxpool_conv.1.double_conv.0.bias\", \"unet.down4.maxpool_conv.1.double_conv.1.weight\", \"unet.down4.maxpool_conv.1.double_conv.1.bias\", \"unet.down4.maxpool_conv.1.double_conv.1.running_mean\", \"unet.down4.maxpool_conv.1.double_conv.1.running_var\", \"unet.down4.maxpool_conv.1.double_conv.1.num_batches_tracked\", \"unet.down4.maxpool_conv.1.double_conv.3.weight\", \"unet.down4.maxpool_conv.1.double_conv.3.bias\", \"unet.down4.maxpool_conv.1.double_conv.4.weight\", \"unet.down4.maxpool_conv.1.double_conv.4.bias\", \"unet.down4.maxpool_conv.1.double_conv.4.running_mean\", \"unet.down4.maxpool_conv.1.double_conv.4.running_var\", \"unet.down4.maxpool_conv.1.double_conv.4.num_batches_tracked\", \"unet.up1.conv.double_conv.0.weight\", \"unet.up1.conv.double_conv.0.bias\", \"unet.up1.conv.double_conv.1.weight\", \"unet.up1.conv.double_conv.1.bias\", \"unet.up1.conv.double_conv.1.running_mean\", \"unet.up1.conv.double_conv.1.running_var\", \"unet.up1.conv.double_conv.1.num_batches_tracked\", \"unet.up1.conv.double_conv.3.weight\", \"unet.up1.conv.double_conv.3.bias\", \"unet.up1.conv.double_conv.4.weight\", \"unet.up1.conv.double_conv.4.bias\", \"unet.up1.conv.double_conv.4.running_mean\", \"unet.up1.conv.double_conv.4.running_var\", \"unet.up1.conv.double_conv.4.num_batches_tracked\", \"unet.up2.conv.double_conv.0.weight\", \"unet.up2.conv.double_conv.0.bias\", \"unet.up2.conv.double_conv.1.weight\", \"unet.up2.conv.double_conv.1.bias\", \"unet.up2.conv.double_conv.1.running_mean\", \"unet.up2.conv.double_conv.1.running_var\", \"unet.up2.conv.double_conv.1.num_batches_tracked\", \"unet.up2.conv.double_conv.3.weight\", \"unet.up2.conv.double_conv.3.bias\", \"unet.up2.conv.double_conv.4.weight\", \"unet.up2.conv.double_conv.4.bias\", \"unet.up2.conv.double_conv.4.running_mean\", \"unet.up2.conv.double_conv.4.running_var\", \"unet.up2.conv.double_conv.4.num_batches_tracked\", \"unet.up3.conv.double_conv.0.weight\", \"unet.up3.conv.double_conv.0.bias\", \"unet.up3.conv.double_conv.1.weight\", \"unet.up3.conv.double_conv.1.bias\", \"unet.up3.conv.double_conv.1.running_mean\", \"unet.up3.conv.double_conv.1.running_var\", \"unet.up3.conv.double_conv.1.num_batches_tracked\", \"unet.up3.conv.double_conv.3.weight\", \"unet.up3.conv.double_conv.3.bias\", \"unet.up3.conv.double_conv.4.weight\", \"unet.up3.conv.double_conv.4.bias\", \"unet.up3.conv.double_conv.4.running_mean\", \"unet.up3.conv.double_conv.4.running_var\", \"unet.up3.conv.double_conv.4.num_batches_tracked\", \"unet.up4.conv.double_conv.0.weight\", \"unet.up4.conv.double_conv.0.bias\", \"unet.up4.conv.double_conv.1.weight\", \"unet.up4.conv.double_conv.1.bias\", \"unet.up4.conv.double_conv.1.running_mean\", \"unet.up4.conv.double_conv.1.running_var\", \"unet.up4.conv.double_conv.1.num_batches_tracked\", \"unet.up4.conv.double_conv.3.weight\", \"unet.up4.conv.double_conv.3.bias\", \"unet.up4.conv.double_conv.4.weight\", \"unet.up4.conv.double_conv.4.bias\", \"unet.up4.conv.double_conv.4.running_mean\", \"unet.up4.conv.double_conv.4.running_var\", \"unet.up4.conv.double_conv.4.num_batches_tracked\", \"unet.outc.conv.weight\", \"unet.outc.conv.bias\". \n\tsize mismatch for l0.weight: copying a param with shape torch.Size([128, 1536]) from checkpoint, the shape in current model is torch.Size([2, 1536]).\n\tsize mismatch for l0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "def post_process(selected):\n",
    "    return \" \".join(set(selected.lower().split()))\n",
    "\n",
    "final_output = submit()\n",
    "sample = pd.read_csv(\"../output/sample_submission.csv\")\n",
    "sample.loc[:, 'selected_text'] = final_output\n",
    "\n",
    "sample.selected_text = sample.selected_text.map(post_process)\n",
    "sample.to_csv(\"../output/submission.csv\", index=False)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
