{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len, training=True):\n",
    "    input_ids = np.ones(max_len)\n",
    "    masks = np.zeros(max_len)\n",
    "    token_type_ids = np.zeros(max_len)\n",
    "    targets_start = 0\n",
    "    targets_end = 0\n",
    "    tweet_offsets = [(0,0) for _ in range(max_len)]\n",
    "    sentiment_id = {s:tokenizer.encode(s)[0] for s in ['positive', 'negative', 'neutral']}\n",
    "    text1 = \" \" + \" \".join(tweet.split())\n",
    "    #print(text1)\n",
    "    enc = tokenizer.encode(text1)\n",
    "    s_tok = sentiment_id[sentiment]\n",
    "    input_ids[:len(enc)+5] = [0] + enc + [2,2] + [s_tok] + [2]\n",
    "    masks[:len(enc)+5] = 1\n",
    "\n",
    "    if training:\n",
    "        text2 = \" \".join(selected_text.split())\n",
    "        idx = text1.find(text2)\n",
    "        #print(idx, enc)\n",
    "        chars = np.zeros((len(text1)))\n",
    "        chars[idx:idx+len(text2)]=1\n",
    "        #if text1[idx-1]==' ': chars[idx-1] = 1 \n",
    "        # ID_OFFSETS\n",
    "        idx=0\n",
    "        for i, t in enumerate(enc):\n",
    "            w = tokenizer.convert_ids_to_tokens([t])[0]\n",
    "            #print(t, w, len(w))\n",
    "            tweet_offsets[i] = (idx,idx+len(w))\n",
    "            idx += len(w)\n",
    "        # START END TOKENS\n",
    "        #print(text1,chars,tweet_offsets)\n",
    "        toks = []\n",
    "        for i,(a,b) in enumerate(tweet_offsets):\n",
    "            sm = np.sum(chars[a:b])\n",
    "            #print(sm, len(chars[a:b]))\n",
    "            #print(i, sm, a,b, chars, chars[a:b])\n",
    "            if sm>0: toks.append(i) \n",
    "        #print('toks',toks)\n",
    "        if len(toks)>0:\n",
    "            targets_start = toks[0]+1\n",
    "            targets_end = toks[-1]+1\n",
    "        #print(targets_start,targets_end)\n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'masks': masks,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(train_sentiment, multiple = 1):\n",
    "    def aug(row):\n",
    "        tweet = row['text']\n",
    "        selected_text = row['selected_text']\n",
    "        idx = tweet.find(selected_text) \n",
    "        if idx>=0:\n",
    "            new_tweets = []\n",
    "            prev = tweet[:idx].split()\n",
    "            after = tweet[idx+len(selected_text):].split()\n",
    "            pool = [(i,j) for i in range(len(prev)+1) for j in range(len(after)+1)]\n",
    "            pool.remove((len(prev),len(after)))\n",
    "            if len(pool) == 0:\n",
    "                return None\n",
    "            for r in np.random.choice(len(pool), multiple):\n",
    "                r1, r2 = pool[r]\n",
    "                start = ''\n",
    "                end = ''\n",
    "                if r1 > 0:\n",
    "                    start =' '.join(prev[r1:]) + ' '\n",
    "                if r2 > 0:\n",
    "                    end = ' '+' '.join(after[:r2])\n",
    "                \n",
    "                new_tweets.append(start+selected_text+end)\n",
    "            if len(new_tweets) > 0:\n",
    "                return new_tweets\n",
    "            return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    train_aug = {'text':[],'selected_text':[], 'sentiment':[], 'textID':[]}\n",
    "    for row in train_sentiment.iterrows():\n",
    "        row = row[1]\n",
    "        new_tweets = aug(row)\n",
    "        if new_tweets:\n",
    "            for new_tweet in new_tweets:\n",
    "                train_aug['text'].append(new_tweet)\n",
    "                train_aug['selected_text'].append(row['selected_text'])\n",
    "                train_aug['sentiment'].append(row['sentiment'])\n",
    "                train_aug['textID'].append(row['textID'])\n",
    "    train_aug = pd.DataFrame(train_aug).dropna()\n",
    "    return train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import tokenizers\n",
    "MAX_LEN = 108\n",
    "TRAINING_FILE = \"../input/tweet-sentiment-extraction/train.csv\"\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "XLNet_PATH = \"../input/xlnet_cased/xlnet_base_cased/\"\n",
    "TOKENIZER = transformers.XLNetTokenizer.from_pretrained('../input/xlnet_cased/xlnet_base_cased/', \n",
    "                                                        remove_space=False,\n",
    "                                                        do_lower_case=True)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(transformers.XLNetLMHeadModel):\n",
    "    def __init__(self, conf):\n",
    "        super(TweetModel, self).__init__(conf)\n",
    "        self.xlnet = transformers.XLNetModel.from_pretrained(XLNet_PATH,config=conf)\n",
    "        self.drop_out = nn.Dropout(0.3)\n",
    "        self.l0 = nn.Linear(768, 2)\n",
    "        torch.nn.init.normal_(self.l0.weight, std=0.02)\n",
    "        self.conv1d_1 = nn.Conv1d(MAX_LEN, 64, 3, padding=1)\n",
    "        self.conv1d_2 = nn.Conv1d(64, 2, 3, padding=1)\n",
    "    \n",
    "    def forward(self, ids, masks, token_type_ids):\n",
    "        _, out = self.xlnet(\n",
    "            ids,\n",
    "            attention_mask=masks,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        out = torch.stack((out[-1], out[-2], out[-3]),dim=0)\n",
    "        out = torch.mean(out, 0)\n",
    "        #out = torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out = self.drop_out(out)\n",
    "        logits = self.l0(out)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        return start_logits, end_logits\n",
    "\n",
    "class TweetDataset:\n",
    "    def __init__(self, tweet, sentiment, selected_text, training):\n",
    "        self.tweet = tweet\n",
    "        self.sentiment = sentiment\n",
    "        self.selected_text = selected_text\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "        self.training = training\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = process_data(\n",
    "            self.tweet[item], \n",
    "            self.selected_text[item], \n",
    "            self.sentiment[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len,\n",
    "            self.training\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            'masks': torch.tensor(data[\"masks\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
    "            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
    "            'orig_tweet': data[\"orig_tweet\"],\n",
    "            'orig_selected': data[\"orig_selected\"],\n",
    "            'sentiment': data[\"sentiment\"],\n",
    "            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = (start_loss + end_loss)\n",
    "    #L.BinaryJaccardLogLoss()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    losses = utils.AverageMeter()\n",
    "    jaccards = utils.AverageMeter()\n",
    "\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    \n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        masks = d[\"masks\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"]\n",
    "    \n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        masks = masks.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs_start, outputs_end = model(\n",
    "            ids=ids,\n",
    "            masks=masks,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        jaccard_scores = []\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            jaccard_score, _ = utils.calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                sentiment_val=tweet_sentiment,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                offsets=offsets[px],\n",
    "                tokenizer=TOKENIZER,\n",
    "            )\n",
    "            jaccard_scores.append(jaccard_score)\n",
    "\n",
    "        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "        losses.update(loss.item(), ids.size(0))\n",
    "        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    losses = utils.AverageMeter()\n",
    "    jaccards = utils.AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for bi, d in enumerate(tk0):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            masks = d[\"masks\"]\n",
    "            sentiment = d[\"sentiment\"]\n",
    "            orig_selected = d[\"orig_selected\"]\n",
    "            orig_tweet = d[\"orig_tweet\"]\n",
    "            targets_start = d[\"targets_start\"]\n",
    "            targets_end = d[\"targets_end\"]\n",
    "            offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            masks = masks.to(device, dtype=torch.long)\n",
    "            targets_start = targets_start.to(device, dtype=torch.long)\n",
    "            targets_end = targets_end.to(device, dtype=torch.long)\n",
    "            \n",
    "            outputs_start, outputs_end = model(\n",
    "                ids=ids,\n",
    "                masks=masks,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "            jaccard_scores = []\n",
    "            for px, tweet in enumerate(orig_tweet):\n",
    "                selected_tweet = orig_selected[px]\n",
    "                tweet_sentiment = sentiment[px]\n",
    "                jaccard_score, _ = utils.calculate_jaccard_score(\n",
    "                    original_tweet=tweet,\n",
    "                    target_string=selected_tweet,\n",
    "                    sentiment_val=tweet_sentiment,\n",
    "                    idx_start=np.argmax(outputs_start[px, :]),\n",
    "                    idx_end=np.argmax(outputs_end[px, :]),\n",
    "                    offsets=offsets[px],\n",
    "                    tokenizer=TOKENIZER\n",
    "                )\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "            losses.update(loss.item(), ids.size(0))\n",
    "            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
    "    \n",
    "    return jaccards.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "indexes = []\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(train['text'],train['sentiment']):\n",
    "    indexes.append((train_index, test_index))\n",
    "\n",
    "jac_folds = []\n",
    "def run(fold=0):\n",
    "    train_index, test_index = indexes[fold]\n",
    "    df_train, df_valid = train.iloc[train_index], train.iloc[test_index]\n",
    "    #df_train= df_train[df_train['sentiment']!='neutral']\n",
    "    df_train = pd.concat([df_train, data_aug(df_train,0)], axis=0, sort=False)\n",
    "    #train_test_split(train_sentiment, test_size=0.2)\n",
    "    \n",
    "    train_dataset = TweetDataset(\n",
    "        tweet=df_train.text.values,\n",
    "        sentiment=df_train.sentiment.values,\n",
    "        selected_text=df_train.selected_text.values,\n",
    "        training=True\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        shuffle=True, \n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "    valid_dataset = TweetDataset(\n",
    "        tweet=df_valid.text.values,\n",
    "        sentiment=df_valid.sentiment.values,\n",
    "        selected_text=df_valid.selected_text.values,\n",
    "        training=True\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        shuffle=False, \n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    model_config = transformers.XLNetConfig.from_pretrained(\"../input/xlnet_cased/xlnet_base_cased/config.json\")\n",
    "    model_config.output_hidden_states = True\n",
    "    model = TweetModel(conf=model_config)    \n",
    "    model.to(device)\n",
    "\n",
    "    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0006},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=4e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "    \n",
    "    es = utils.EarlyStopping(patience=2)\n",
    "    print(f\"Training is Starting for fold={fold}\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n",
    "        jaccard = eval_fn(valid_data_loader, model, device)\n",
    "        print(f\"Jaccard Score = {jaccard}\")\n",
    "        es(jaccard, model)\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    jac_folds.append(jaccard)\n",
    "    torch.save(model.state_dict(), f\"XLNetmodel_{fold}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6021f3365ea148b7af4534ba5f717f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1405f47d96bb4a2ca5aecec55b6b7f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6988950205599564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5fcfea99f34accaaea7f823f3180dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63520ea6be994070aa8ee3e16711c572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7071640970816213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707d8f110b0c4c75af97d7dae618cafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bc7ee624d64bcf859363517aac1215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7082537812626892\n",
      "Training is Starting for fold=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51285fdf7424b8abad19b01b41c1516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d874d4edb7374be89eebb7130e361fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6889587184918052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00d446a40df499a854d2f298ed7fcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1392fa401f2745f2befcc78d6bdd303e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7023902385226309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233d45c8d28f413285898b517cced951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ba0e60a1e249028de6b124c23b4dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7081705955958753\n",
      "Training is Starting for fold=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff9db0b19e74ca5a6b29b0b71bf4d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ff6cd0cec34e23bdcb07c411153273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.696553309773101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c555da2ef13a45dfa361a8bf9801f9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c16606ddd24092933b24b83c13dde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7030382110631687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500f51664099420eb732b6dabfcbb305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eeb157ff9ab4fb395f947f159498838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7036598453726495\n",
      "Training is Starting for fold=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2209de9480784dc5ab0be936616c027d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee875d8c54074129bbc11dda73b77e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6970969686565768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231af262e985465aa646238e44dcb88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5604187990c148e68cc494b39e19e4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7075787210707901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c0b0fa125d451bb4d21720589e78c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34860f8a855433e92796d1bd9653bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7103120878250555\n",
      "Training is Starting for fold=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11b786ce97f4111b3bb207014dd60bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43635dafebf94b34a022d5c7bfbc738c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.6929098674034506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c180de57e57649549904f3522dd01654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1aa95a28fe64efb8202942a85907349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7003127411942135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ddaa9bd5a54cd788340338f110a57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fb48d2de114ccab441d774e526c8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score = 0.7024750791190862\n",
      "folds mean =  0.7065742778350712\n"
     ]
    }
   ],
   "source": [
    "run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)\n",
    "print('folds mean = ', np.mean(jac_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(train, verbose=0):\n",
    "    jacs =[]\n",
    "    for x in train.index:\n",
    "        tweet=train.loc[x, 'text']\n",
    "        selected_text = train.loc[x, 'selected_text']\n",
    "        sentiment=train.loc[x, 'sentiment']\n",
    "        tokenizer=TOKENIZER\n",
    "        max_len=MAX_LEN\n",
    "        d=process_data(tweet, selected_text, sentiment, tokenizer, max_len, training=True)\n",
    "        decoded=utils.calculate_jaccard_score(\n",
    "                        original_tweet=d['orig_tweet'],\n",
    "                        target_string=d['orig_selected'],\n",
    "                        sentiment_val=d['sentiment'],\n",
    "                        idx_start=d['targets_start'],\n",
    "                        idx_end=d['targets_end'],\n",
    "                        offsets=d['offsets'],\n",
    "                        tokenizer=TOKENIZER\n",
    "                    )\n",
    "        if verbose:\n",
    "            print(tweet,selected_text,decoded)\n",
    "        jacs.append(decoded[0])\n",
    "    return np.mean(jacs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference():\n",
    "    df_test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n",
    "    df_test['text'] = df_test['text'].astype(str)\n",
    "    model_config = transformers.XLNetConfig.from_pretrained(\"../input/xlnet_cased/xlnet_base_cased/config.json\")\n",
    "    model_config.output_hidden_states = True\n",
    "    test_dataset = TweetDataset(\n",
    "        tweet=df_test.text.values,\n",
    "        sentiment=df_test.sentiment.values,\n",
    "        selected_text=np.zeros(len(df_test)),\n",
    "        training=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=32, \n",
    "            shuffle=False, \n",
    "            num_workers=2)    \n",
    "    predictions = []\n",
    "    models = []\n",
    "    for fold in range(2):\n",
    "        model = TweetModel(conf=model_config)\n",
    "        model.cuda()\n",
    "        model.load_state_dict(torch.load(f'XLNetmodel_{fold}.bin'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "\n",
    "    for data in test_loader:\n",
    "        ids = data['ids'].cuda()\n",
    "        masks = data['masks'].cuda()\n",
    "        tweet = data['orig_tweet']\n",
    "        offsets = data['offsets'].numpy()\n",
    "        sentiment = data['sentiment']\n",
    "        token_type_ids = data['token_type_ids'].cuda()\n",
    "\n",
    "        start_logits = []\n",
    "        end_logits = []\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                output = model(ids, masks,token_type_ids)\n",
    "                start_logits.append(torch.softmax(output[0], dim=1).cpu().detach().numpy())\n",
    "                end_logits.append(torch.softmax(output[1], dim=1).cpu().detach().numpy())\n",
    "\n",
    "        start_logits = np.mean(start_logits, axis=0)\n",
    "        end_logits = np.mean(end_logits, axis=0)\n",
    "        for i in range(len(ids)):    \n",
    "            start_pred = np.argmax(start_logits[i])\n",
    "            end_pred = np.argmax(end_logits[i])\n",
    "            _, pred = utils.calculate_jaccard_score(tweet[i],\n",
    "                                    \"\",\n",
    "                                    sentiment[i],\n",
    "                                    start_pred,\n",
    "                                    end_pred,\n",
    "                                    offsets[i],\n",
    "                                    tokenizer=TOKENIZER,\n",
    "                                    verbose=False)\n",
    "            predictions.append(pred)\n",
    "\n",
    "    sub_df = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\n",
    "    sub_df['selected_text'] = predictions\n",
    "    sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\n",
    "    sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\n",
    "    sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n",
    "    sub_df.to_csv('submission.csv', index=False)\n",
    "    sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
